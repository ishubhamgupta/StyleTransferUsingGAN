{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#why GMM?\n",
    "#why graph replace for discimrinator?\n",
    "#slim repeat operation\n",
    "#add 2 references\n",
    "\n",
    "\n",
    "#bridging the python 2 and python 3 gap\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os # saving files\n",
    "import numpy as np #matrix math\n",
    "import pandas\n",
    "\n",
    "#visualizing data\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "#machine learning\n",
    "import tensorflow as tf\n",
    "\n",
    "#gausian mixture model for generating data\n",
    "from data_gmm import GMM_distribution, sample_GMM, plot_GMM\n",
    "#analyzing data \n",
    "from data_utils import shuffle, iter_data\n",
    "\n",
    "#progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "#TF-Slim is a lightweight library for defining, training and evaluating models in TensorFlow. It enables defining complex networks quickly and concisely\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "#Classes that represent batches of statistical distributions. \n",
    "#Each class is initialized with parameters that define the distributions\n",
    "ds = tf.contrib.distributions\n",
    "\n",
    "#Create a new graph which compute the targets from the replaced Tensors.\n",
    "\n",
    "graph_replace = tf.contrib.graph_editor.graph_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hyperparams\n",
    "\"\"\" parameters \"\"\"\n",
    "n_epoch = 1000 #number of epcohs\n",
    "batch_size  = 64\n",
    "dataset_size = 512\n",
    "input_dim = 2 #data and labels\n",
    "latent_dim = 2 \n",
    "eps_dim = 2\n",
    "\n",
    "\n",
    "#discriminator\n",
    "n_layer_disc = 2\n",
    "n_hidden_disc = 256\n",
    "\n",
    "#generator \n",
    "n_layer_gen = 2\n",
    "n_hidden_gen= 256\n",
    "\n",
    "#inference network (generator #2)\n",
    "n_layer_inf = 2\n",
    "n_hidden_inf= 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save our results to the DiscoGAN folder\n",
    "\"\"\" Create directory for results \"\"\"\n",
    "result_dir = 'results/DiscoGAN/'\n",
    "directory = result_dir\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The demo is tested a toy dataset, \n",
    "#5-component GMM\n",
    "#A Gaussian mixture model is a probabilistic model \n",
    "#that assumes all the data points are generated from \n",
    "#a mixture of a finite number of Gaussian distributions \n",
    "#with unknown parameters.\n",
    "\n",
    "# create X dataset (first dataset)\n",
    "#applies a function to all the items in an input_list\n",
    "#lambda = anonymous functions (i.e. function that is not bound to a name)\n",
    "#creates a numpy array of 5 components\n",
    "means = map(lambda x:  np.array(x), [[0, 0],\n",
    "                                     [2, 2],\n",
    "                                     [-1, -1],\n",
    "                                     [1, -1],\n",
    "                                     [-1, 1]])\n",
    "\n",
    "#convert to list to access methods\n",
    "means = list(means)\n",
    "#standard deviation\n",
    "std = 0.1\n",
    "#variances - eye Return an identiy matrix, 2-D array with 1s on the diagonal & 0s elsewhere.\n",
    "variances = [np.eye(2) * std for _ in means]\n",
    "\n",
    "# the probability distribution that would express one's beliefs about this \n",
    "#quantity before some evidence is taken into account\n",
    "priors = [1.0/len(means) for _ in means]\n",
    "\n",
    "#create gaussian mixture model \n",
    "gaussian_mixture = GMM_distribution(means=means,\n",
    "                                               variances=variances,\n",
    "                                               priors=priors)\n",
    "\n",
    "#sample from the data using the GMM\n",
    "dataset = sample_GMM(dataset_size, means, variances, priors, sources=('features', ))\n",
    "\n",
    "#save the results\n",
    "save_path = result_dir + 'X_gmm_data.pdf'\n",
    "#plot the results\n",
    "plot_GMM(dataset, save_path)\n",
    "\n",
    "#store data and labels\n",
    "X_np_data= dataset.data['samples']\n",
    "X_labels = dataset.data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create Z dataset (second dataset)\n",
    "#2-component GMM. \n",
    "means = map(lambda x:  np.array(x), [[-1, -1],[1, 1]])\n",
    "means = list(means)\n",
    "std = 0.1\n",
    "variances = [np.eye(2) * std for _ in means]\n",
    "\n",
    "priors = [1.0/len(means) for _ in means]\n",
    "\n",
    "gaussian_mixture = GMM_distribution(means=means,\n",
    "                                               variances=variances,\n",
    "                                               priors=priors)\n",
    "dataset = sample_GMM(dataset_size, means, variances, priors, sources=('features', ))\n",
    "save_path = result_dir + 'Z_gmm_data.pdf'\n",
    "plot_GMM(dataset, save_path)\n",
    "\n",
    "Z_np_data= dataset.data['samples']\n",
    "Z_labels = dataset.data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# samples of x and z\n",
    "X_dataset = X_np_data\n",
    "Z_dataset = Z_np_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Networks \"\"\"\n",
    "\n",
    "#Each of the two coupled models learns the mapping from\n",
    "#one domain to another, and also the reverse mapping to for\n",
    "#reconstruction. The two models are trained together simultaneously.\n",
    "#The two generators GAB’s and the two generators\n",
    "#GBA’s share parameters, and the generated images\n",
    "#xBA and xAB are each fed into separate discriminators LDA\n",
    "#and LDB , respectively.\n",
    "\n",
    "\n",
    "\n",
    "#2 generators\n",
    "def generative_network(z, input_dim, n_layer, n_hidden, eps_dim):\n",
    "    with tf.variable_scope(\"generative\"):\n",
    "        h = z\n",
    "        #repeat allow us to repeatedly perform the same operation.\n",
    "        #many fully connected layers\n",
    "        h = slim.repeat(h, n_layer, slim.fully_connected, n_hidden, activation_fn=tf.nn.relu)\n",
    "        x = slim.fully_connected(h, input_dim, activation_fn=None, scope=\"p_x\")\n",
    "    return x\n",
    "\n",
    "\n",
    "def inference_network(x, latent_dim, n_layer, n_hidden, eps_dim):\n",
    "    with tf.variable_scope(\"inference\"):\n",
    "        h = x\n",
    "        h = slim.repeat(h, n_layer, slim.fully_connected, n_hidden, activation_fn=tf.nn.relu)\n",
    "        z = slim.fully_connected(h, latent_dim, activation_fn=None, scope=\"q_z\")\n",
    "    return z\n",
    "\n",
    "\n",
    "#2 discriminators\n",
    "def data_network_x(x, n_layers=2, n_hidden=256, activation_fn=None):\n",
    "    \"\"\"Approximate x log data density.\"\"\"\n",
    "    h = tf.concat(x, 1)\n",
    "    with tf.variable_scope('discriminator_x'):\n",
    "        h = slim.repeat(h, n_layers, slim.fully_connected, n_hidden, activation_fn=tf.nn.relu)\n",
    "        log_d = slim.fully_connected(h, 1, activation_fn=activation_fn)\n",
    "    return tf.squeeze(log_d, squeeze_dims=[1]) #Removes dimensions of size 1 \n",
    "    #from the shape of a tensor.\n",
    "\n",
    "\n",
    "\n",
    "def data_network_z(z, n_layers=2, n_hidden=256, activation_fn=None):\n",
    "    \"\"\"Approximate z log data density.\"\"\"\n",
    "    h = tf.concat(z, 1)\n",
    "    with tf.variable_scope('discriminator_z'):\n",
    "        h = slim.repeat(h, n_layers, slim.fully_connected, n_hidden, activation_fn=tf.nn.relu)\n",
    "        log_d = slim.fully_connected(h, 1, activation_fn=activation_fn)\n",
    "    return tf.squeeze(log_d, squeeze_dims=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Copying op: concat\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_x/Repeat/fully_connected_1/MatMul\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_x/Repeat/fully_connected_1/BiasAdd\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_x/Repeat/fully_connected_1/Relu\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_x/Repeat/fully_connected_2/MatMul\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_x/Repeat/fully_connected_2/BiasAdd\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_x/Repeat/fully_connected_2/Relu\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_x/fully_connected/MatMul\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_x/fully_connected/BiasAdd\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: Squeeze\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Finalizing op: concat\n",
      "INFO:tensorflow:Finalizing op: discriminator_x/Repeat/fully_connected_1/MatMul\n",
      "INFO:tensorflow:Finalizing op: discriminator_x/Repeat/fully_connected_1/BiasAdd\n",
      "INFO:tensorflow:Finalizing op: discriminator_x/Repeat/fully_connected_1/Relu\n",
      "INFO:tensorflow:Finalizing op: discriminator_x/Repeat/fully_connected_2/MatMul\n",
      "INFO:tensorflow:Finalizing op: discriminator_x/Repeat/fully_connected_2/BiasAdd\n",
      "INFO:tensorflow:Finalizing op: discriminator_x/Repeat/fully_connected_2/Relu\n",
      "INFO:tensorflow:Finalizing op: discriminator_x/fully_connected/MatMul\n",
      "INFO:tensorflow:Finalizing op: discriminator_x/fully_connected/BiasAdd\n",
      "INFO:tensorflow:Finalizing op: Squeeze\n",
      "INFO:tensorflow:Copying op: concat_2\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_z/Repeat/fully_connected_1/MatMul\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_z/Repeat/fully_connected_1/BiasAdd\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_z/Repeat/fully_connected_1/Relu\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_z/Repeat/fully_connected_2/MatMul\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_z/Repeat/fully_connected_2/BiasAdd\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_z/Repeat/fully_connected_2/Relu\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_z/fully_connected/MatMul\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: discriminator_z/fully_connected/BiasAdd\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Copying op: Squeeze_2\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "INFO:tensorflow:Finalizing op: concat_2\n",
      "INFO:tensorflow:Finalizing op: discriminator_z/Repeat/fully_connected_1/MatMul\n",
      "INFO:tensorflow:Finalizing op: discriminator_z/Repeat/fully_connected_1/BiasAdd\n",
      "INFO:tensorflow:Finalizing op: discriminator_z/Repeat/fully_connected_1/Relu\n",
      "INFO:tensorflow:Finalizing op: discriminator_z/Repeat/fully_connected_2/MatMul\n",
      "INFO:tensorflow:Finalizing op: discriminator_z/Repeat/fully_connected_2/BiasAdd\n",
      "INFO:tensorflow:Finalizing op: discriminator_z/Repeat/fully_connected_2/Relu\n",
      "INFO:tensorflow:Finalizing op: discriminator_z/fully_connected/MatMul\n",
      "INFO:tensorflow:Finalizing op: discriminator_z/fully_connected/BiasAdd\n",
      "INFO:tensorflow:Finalizing op: Squeeze_2\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Construct model and training ops \"\"\"\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#data1 input\n",
    "x = tf.placeholder(tf.float32, shape=(batch_size, input_dim))\n",
    "#data 2 input\n",
    "z = tf.placeholder(tf.float32, shape=(batch_size, latent_dim))\n",
    "\n",
    "# 2 generators - encoders\n",
    "p_x = generative_network(z, input_dim , n_layer_gen, n_hidden_gen, eps_dim)\n",
    "q_z = inference_network(x, latent_dim, n_layer_inf, n_hidden_inf, eps_dim)\n",
    "\n",
    "#The logit function is the inverse of the sigmoidal \"logistic\" function\n",
    "\n",
    "#2 discriminators\n",
    "decoder_logit_x = data_network_x(p_x, n_layers=n_layer_disc, n_hidden=n_hidden_disc)\n",
    "encoder_logit_x = graph_replace(decoder_logit_x, {p_x: x})\n",
    "\n",
    "decoder_logit_z = data_network_z(q_z, n_layers=n_layer_disc, n_hidden=n_hidden_disc)\n",
    "encoder_logit_z = graph_replace(decoder_logit_z, {q_z: z})\n",
    "\n",
    "#Computes softplus: log(exp(features) + 1). activation\n",
    "#for calculating loss\n",
    "encoder_sigmoid_x = tf.nn.softplus(encoder_logit_x)\n",
    "decoder_sigmoid_x = tf.nn.softplus(decoder_logit_x)\n",
    "encoder_sigmoid_z = tf.nn.softplus(encoder_logit_z)\n",
    "decoder_sigmoid_z = tf.nn.softplus(decoder_logit_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loss functions\n",
    "\n",
    "#loss for both discriminators\n",
    "decoder_loss = decoder_sigmoid_x + decoder_sigmoid_z\n",
    "encoder_loss = encoder_sigmoid_x + encoder_sigmoid_z\n",
    "\n",
    "#combined loss for discriminators\n",
    "disc_loss = tf.reduce_mean(  encoder_loss ) - tf.reduce_mean( decoder_loss)\n",
    "\n",
    "#2 more generators (decoders)\n",
    "rec_z = inference_network(p_x, latent_dim, n_layer_inf, n_hidden_inf, eps_dim )\n",
    "rec_x = generative_network(q_z, input_dim , n_layer_gen, n_hidden_gen,  eps_dim )\n",
    "\n",
    "#compute generator loss\n",
    "#Sum of Squared Error loss\n",
    "cost_z = tf.reduce_mean(tf.pow(rec_z - z, 2))\n",
    "cost_x = tf.reduce_mean(tf.pow(rec_x - x, 2))\n",
    "#we tie in discriminator loss into generators loss\n",
    "adv_loss = tf.reduce_mean(  decoder_loss ) \n",
    "gen_loss = 1*adv_loss + 1.*cost_x  + 1.*cost_z\n",
    "\n",
    "#collect vars with names that contain this\n",
    "qvars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"inference\")\n",
    "pvars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"generative\")\n",
    "dvars_x = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"discriminator_x\")\n",
    "dvars_z = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"discriminator_z\")\n",
    "\n",
    "#use adam (gradient descent) to optimize\n",
    "opt = tf.train.AdamOptimizer(1e-4, beta1=0.5)\n",
    "\n",
    "#minimize generators loss\n",
    "train_gen_op =  opt.minimize(gen_loss, var_list=qvars + pvars)\n",
    "\n",
    "#minimize discirimaintors loss\n",
    "train_disc_op = opt.minimize(disc_loss, var_list=dvars_x + dvars_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [06:13<00:00,  2.65it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" training \"\"\"\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "FG = []\n",
    "FD = []\n",
    "\n",
    "#for each epoch (log the status bar)\n",
    "for epoch in tqdm( range(n_epoch), total=n_epoch):\n",
    "    #sample from both our datasets\n",
    "    X_dataset, Z_dataset= shuffle(X_dataset, Z_dataset)\n",
    "\n",
    "    #for each x and z in our data \n",
    "    for xmb, zmb in iter_data(X_dataset, Z_dataset, size=batch_size):\n",
    "        \n",
    "        #minimize our loss functions\n",
    "        for _ in range(1):\n",
    "            f_d, _ = sess.run([disc_loss, train_disc_op], feed_dict={x: xmb, z:zmb})\n",
    "        for _ in range(5):\n",
    "            #3 components that make up generator loss\n",
    "            f_g, _ = sess.run([[adv_loss, cost_x, cost_z], train_gen_op], feed_dict={x: xmb, z:zmb})\n",
    "\n",
    "        FG.append(f_g)\n",
    "        FD.append(f_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" plot the results \"\"\"\n",
    "\n",
    "n_viz = 1\n",
    "imz = np.array([]); rmz = np.array([]); imx = np.array([]); rmx = np.array([]);\n",
    "for _ in range(n_viz):\n",
    "    for xmb, zmb in iter_data(X_np_data, Z_np_data, size=batch_size):\n",
    "        temp_imz = sess.run(q_z, feed_dict={x: xmb, z:zmb})\n",
    "        imz = np.vstack([imz, temp_imz]) if imz.size else temp_imz\n",
    "\n",
    "        temp_rmz = sess.run(rec_z, feed_dict={x: xmb, z:zmb})\n",
    "        rmz = np.vstack([rmz, temp_rmz]) if rmz.size else temp_rmz\n",
    "\n",
    "        temp_imx = sess.run(p_x, feed_dict={x: xmb, z:zmb})\n",
    "        imx = np.vstack([imx, temp_imx]) if imx.size else temp_imx\n",
    "\n",
    "        temp_rmx = sess.run(rec_x, feed_dict={x: xmb, z:zmb})\n",
    "        rmx = np.vstack([rmx, temp_rmx]) if rmx.size else temp_rmx\n",
    "\n",
    "## inferred marginal z\n",
    "fig_mz, ax = plt.subplots(nrows=1, ncols=1, figsize=(4.5, 4.5))\n",
    "ll = np.tile(X_labels, (n_viz))\n",
    "ax.scatter(imz[:, 0], imz[:, 1], c=cm.Set1(ll.astype(float)/input_dim/2.0),\n",
    "        edgecolor='none', alpha=0.5)\n",
    "ax.set_xlim(-3, 3); ax.set_ylim(-3.5, 3.5)\n",
    "ax.set_xlabel('$z_1$'); ax.set_ylabel('$z_2$')\n",
    "ax.axis('on')\n",
    "plt.savefig(result_dir + 'inferred_mz.pdf', transparent=True, bbox_inches='tight')\n",
    "\n",
    "##  reconstruced z\n",
    "fig_pz, ax = plt.subplots(nrows=1, ncols=1, figsize=(4.5, 4.5))\n",
    "ll = np.tile(Z_labels, (n_viz))\n",
    "ax.scatter(rmz[:, 0], rmz[:, 1], c=cm.Set1(ll.astype(float)/input_dim/2.0),\n",
    "           edgecolor='none', alpha=0.5)\n",
    "ax.set_xlim(-3, 3); ax.set_ylim(-3.5, 3.5)\n",
    "ax.set_xlabel('$z_1$'); ax.set_ylabel('$z_2$')\n",
    "ax.axis('on')\n",
    "plt.savefig(result_dir + 'reconstruct_mz.pdf', transparent=True, bbox_inches='tight')\n",
    "\n",
    "## inferred marginal x\n",
    "fig_pz, ax = plt.subplots(nrows=1, ncols=1, figsize=(4.5, 4.5))\n",
    "ll = np.tile(Z_labels, (n_viz))\n",
    "ax.scatter(imx[:, 0], imx[:, 1], c=cm.Set1(ll.astype(float)/input_dim/2.0),\n",
    "        edgecolor='none', alpha=0.5)\n",
    "ax.set_xlim(-3, 3); ax.set_ylim(-3.5, 3.5)\n",
    "ax.set_xlabel('$x_1$'); ax.set_ylabel('$x_2$')\n",
    "ax.axis('on')\n",
    "plt.savefig(result_dir + 'inferred_mx.pdf', transparent=True, bbox_inches='tight')\n",
    "\n",
    "##  reconstruced x\n",
    "fig_mx, ax = plt.subplots(nrows=1, ncols=1, figsize=(4.5, 4.5))\n",
    "ll = np.tile(X_labels, (n_viz))\n",
    "ax.scatter(rmx[:, 0], rmx[:, 1], c=cm.Set1(ll.astype(float)/input_dim/2.0),\n",
    "           edgecolor='none', alpha=0.5)\n",
    "ax.set_xlim(-3, 3); ax.set_ylim(-3.5, 3.5)\n",
    "ax.set_xlabel('$x_1$'); ax.set_ylabel('$x_2$')\n",
    "ax.axis('on')\n",
    "plt.savefig(result_dir + 'reconstruct_mx.pdf', transparent=True, bbox_inches='tight')\n",
    "\n",
    "## learning curves\n",
    "fig_curve, ax = plt.subplots(nrows=1, ncols=1, figsize=(4.5, 4.5))\n",
    "ax.plot(FD, label=\"Discriminator\")\n",
    "ax.plot(np.array(FG)[:,0], label=\"Generator\")\n",
    "ax.plot(np.array(FG)[:,1], label=\"Reconstruction x\")\n",
    "ax.plot(np.array(FG)[:,2], label=\"Reconstruction Z\")\n",
    "plt.xlabel('Iteration')\n",
    "plt.xlabel('Loss')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "ax.axis('on')\n",
    "plt.savefig(result_dir + 'learning_curves.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
